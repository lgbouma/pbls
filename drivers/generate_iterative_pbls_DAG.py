##########################################
# OPTIONS
ntotchunks = 1000
star_id = 'kplr006184894'
snrthreshold = 8
maxiter = 3
##########################################

dag_filename = f"run_iterative_pbls_{star_id}.dag"

header = f"""# run_iterative_pbls_{star_id}.dag
# Run iterative PBLs for star_id {star_id} with {ntotchunks} chunks and {maxiter} iterations.
# Run via `condor_submit_dag -f run_iterative_pbls_{star_id}.dag`
# Generated by generate_iterative_pbls_DAG.py

# ————————————————————————————————
# PBLS Iteration 0: run cleanup, then {ntotchunks} scatter chunks, then merge & mask.
# ————————————————————————————————

# Dummy “setup” job to run PRE‐script on submit node
JOB  Clean_0   /bin/true
SCRIPT PRE  Clean_0   /usr/bin/python3 clean_directories.py {star_id}
RETRY  Clean_0  1

# Scatter jobs for the first PBLS iteration
"""

scatter_lines = []
for period_chunk_ix in range(ntotchunks):
    pstr = f"{str(period_chunk_ix).zfill(4)}"
    scatter_line = f"""JOB Scatter_0_{pstr}  scatter_single_pbls_iter0.sub
VARS Scatter_0_{pstr} star_id="{star_id}" iter_ix="0" ntotchunks="{ntotchunks}" period_chunk_ix="{period_chunk_ix}"
RETRY Scatter_0_{pstr} 3
PARENT Clean_0 CHILD Scatter_0_{pstr}
"""
    scatter_lines.append(scatter_line)

merge_lines = f"""JOB Merge_0 merge.sub
VARS Merge_0 star_id="{star_id}" iter_ix="0" threshold="{snrthreshold}" maxiter="{maxiter}"
RETRY Merge_0 1
"""
parent_scatter_line = "PARENT " + ",".join([f"Scatter_0_{str(ix).zfill(4)}" for ix in range(ntotchunks)]) + " CHILD Merge_0"
merge_lines += parent_scatter_line + "\n"

mask_lines = f"""JOB Mask_0 mask.sub
VARS Mask_0 star_id="{star_id}" iter_ix="0" threshold="{snrthreshold}" maxiter="{maxiter}"
RETRY Mask_0 1
PARENT Merge_0 CHILD Mask_0
"""

lines = (
    header +
    "\n".join(scatter_lines) +
    "\n" +
    "# Merge scatter jobs\n" +
    merge_lines +
    "\n" +
    "# Mask light curve\n" +
    mask_lines
)

for iter_ix in range(1, maxiter):

    header = f"""# ————————————————————————————————
# PBLS Iteration {iter_ix}
# ————————————————————————————————
"""

    scatter_lines = []
    for period_chunk_ix in range(ntotchunks):
        pstr = f"{str(period_chunk_ix).zfill(4)}"
        scatter_line = f"""JOB Scatter_{iter_ix}_{pstr}  scatter_single_pbls_iterN.sub
VARS Scatter_{iter_ix}_{pstr} star_id="{star_id}" iter_ix="{iter_ix}" ntotchunks="{ntotchunks}" period_chunk_ix="{period_chunk_ix}"
RETRY Scatter_{iter_ix}_{pstr} 3
PARENT Mask_{int(iter_ix - 1)} CHILD Scatter_{iter_ix}_{pstr}
"""
        scatter_lines.append(scatter_line)

    merge_lines = f"""JOB Merge_{iter_ix} merge.sub
VARS Merge_{iter_ix} star_id="{star_id}" iter_ix="{iter_ix}" threshold="{snrthreshold}" maxiter="{maxiter}"
RETRY Merge_{iter_ix} 1
"""
    parent_scatter_line = "PARENT " + ",".join([f"Scatter_{iter_ix}_{str(ix).zfill(4)}" for ix in range(ntotchunks)]) + f" CHILD Merge_{iter_ix}"
    merge_lines += parent_scatter_line + "\n"

    mask_lines = f"""JOB Mask_{iter_ix} mask.sub
VARS Mask_{iter_ix} star_id="{star_id}" iter_ix="{iter_ix}" threshold="{snrthreshold}" maxiter="{maxiter}"
RETRY Mask_{iter_ix} 1
PARENT Merge_{iter_ix} CHILD Mask_{iter_ix}
"""

    iterlines = header + "\n" + "\n".join(scatter_lines) + "\n" + merge_lines + "\n" + mask_lines

    lines += "\n" + iterlines + "\n"

with open(dag_filename, "w") as f:
    f.writelines(lines) 
print(f"DAG file '{dag_filename}' generated for star_id '{star_id}' with {ntotchunks} chunks and {maxiter} iterations.")