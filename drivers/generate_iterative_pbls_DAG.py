##########################################
# CLI OPTIONS
# Defaults per request:
# - ntotchunks = 200
# - star_id = None (must be provided by caller)
# - snrthreshold = 8
# - maxiter = 2
##########################################
import argparse

parser = argparse.ArgumentParser(description="Generate a DAG for iterative PBLS runs.")
parser.add_argument("--ntotchunks", type=int, default=200, help="Total number of period chunks (default: 200)")
parser.add_argument("--star_id", type=str, default=None, help="Star identifier, e.g., kplr008653134 or kplr008653134_inject-P4p898-R1p2-T2p6-E1p234")
parser.add_argument("--snrthreshold", type=float, default=8, help="SNR threshold for masking (default: 8)")
parser.add_argument("--maxiter", type=int, default=2, help="Maximum number of iterations (default: 2)")

args = parser.parse_args()

ntotchunks = int(args.ntotchunks)
star_id = args.star_id
snrthreshold = args.snrthreshold
maxiter = int(args.maxiter)

if star_id is None:
    raise SystemExit("Error: --star_id must be provided.")

dag_filename = f"run_iterative_pbls_{star_id}.dag"

header = f"""# run_iterative_pbls_{star_id}.dag
# Run iterative PBLS for star_id {star_id} with {ntotchunks} chunks and {maxiter} iterations.
# Run via `condor_submit_dag -f run_iterative_pbls_{star_id}.dag`
# Generated by generate_iterative_pbls_DAG.py

# ————————————————————————————————
# PBLS Iteration 0: run cleanup, then {ntotchunks} scatter chunks, then merge & mask.
# ————————————————————————————————

# Dummy “setup” job to run PRE‐script on submit node
JOB    Clean_0   clean.sub
SCRIPT PRE  Clean_0   /usr/bin/python3 clean_directories.py {star_id}
RETRY  Clean_0   1

# Scatter jobs for the first PBLS iteration
"""

scatter_lines = []
for period_chunk_ix in range(ntotchunks):
    pstr = f"{str(period_chunk_ix).zfill(4)}"
    scatter_line = f"""JOB Scatter_0_{pstr}  scatter_single_pbls_iter0.sub
VARS Scatter_0_{pstr} star_id="{star_id}" iter_ix="0" ntotchunks="{ntotchunks}" period_chunk_ix="{period_chunk_ix}"
RETRY Scatter_0_{pstr} 3
PARENT Clean_0 CHILD Scatter_0_{pstr}
"""
    scatter_lines.append(scatter_line)

merge_lines = f"""JOB Merge_0 merge.sub
VARS Merge_0 star_id="{star_id}" iter_ix="0" threshold="{snrthreshold}" maxiter="{maxiter}"
RETRY Merge_0 1
"""
parent_scatter_line = "PARENT " + " ".join([f"Scatter_0_{str(ix).zfill(4)}" for ix in range(ntotchunks)]) + " CHILD Merge_0"
merge_lines += parent_scatter_line + "\n"

pgproc_lines = f"""JOB PgProc_0 periodogram_processing.sub
VARS PgProc_0 star_id="{star_id}" iter_ix="0"
RETRY PgProc_0 1
PARENT Merge_0 CHILD PgProc_0
"""

mask_lines = f"""JOB Mask_0 mask.sub
VARS Mask_0 star_id="{star_id}" iter_ix="0" threshold="{snrthreshold}" maxiter="{maxiter}"
RETRY Mask_0 1
PARENT PgProc_0 CHILD Mask_0
"""

lines = (
    header +
    "\n".join(scatter_lines) +
    "\n" +
    "# Merge scatter jobs\n" +
    merge_lines +
    "\n" +
    "# Process periodogram\n" +
    pgproc_lines +
    "\n" +
    "# Mask light curve\n" +
    mask_lines
)

#############################
# ALL SUBSEQUENT ITERATIONS #
#############################
for iter_ix in range(1, maxiter):

    prev_ix = int(iter_ix - 1)

    header = f"""# ————————————————————————————————
# PBLS Iteration {iter_ix}
# ————————————————————————————————
"""

    scatter_lines = []
    for period_chunk_ix in range(ntotchunks):
        pstr = f"{str(period_chunk_ix).zfill(4)}"
        scatter_line = f"""JOB Scatter_{iter_ix}_{pstr}  scatter_single_pbls_iterN.sub
VARS Scatter_{iter_ix}_{pstr} star_id="{star_id}" iter_ix="{iter_ix}" ntotchunks="{ntotchunks}" period_chunk_ix="{period_chunk_ix}" prev_ix="{prev_ix}"
RETRY Scatter_{iter_ix}_{pstr} 3
PARENT Mask_{prev_ix} CHILD Scatter_{iter_ix}_{pstr}
"""
        scatter_lines.append(scatter_line)

    merge_lines = f"""JOB Merge_{iter_ix} merge.sub
VARS Merge_{iter_ix} star_id="{star_id}" iter_ix="{iter_ix}" threshold="{snrthreshold}" maxiter="{maxiter}"
RETRY Merge_{iter_ix} 1
"""
    parent_scatter_line = "PARENT " + " ".join([f"Scatter_{iter_ix}_{str(ix).zfill(4)}" for ix in range(ntotchunks)]) + f" CHILD Merge_{iter_ix}"
    merge_lines += parent_scatter_line + "\n"

    pgproc_lines = f"""JOB PgProc_{iter_ix} periodogram_processing.sub
VARS PgProc_{iter_ix} star_id="{star_id}" iter_ix="{iter_ix}"
RETRY PgProc_{iter_ix} 1
PARENT Merge_{iter_ix} CHILD PgProc_{iter_ix}
"""

    mask_lines = f"""JOB Mask_{iter_ix} mask.sub
VARS Mask_{iter_ix} star_id="{star_id}" iter_ix="{iter_ix}" threshold="{snrthreshold}" maxiter="{maxiter}"
RETRY Mask_{iter_ix} 1
PARENT PgProc_{iter_ix} CHILD Mask_{iter_ix}
"""

    iterlines = header + "\n" + "\n".join(scatter_lines) + "\n" + merge_lines + "\n" + pgproc_lines + "\n" + mask_lines

    lines += "\n" + iterlines + "\n"

with open(dag_filename, "w") as f:
    f.writelines(lines) 
print(f"DAG file '{dag_filename}' generated for star_id '{star_id}' with {ntotchunks} chunks and {maxiter} iterations.")
