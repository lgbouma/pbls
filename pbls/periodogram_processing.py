"""
Contents:

    trimmean_whitening: Applies a sliding trim mean filter to the periodogram.
    iterative_gaussian_whitening: Iteratively fits and subtracts Gaussian peaks from a periodogram.

Bonus:
    find_contiguous_width: Finds the width of a contiguous region above a baseline in a periodogram.
"""
import numpy as np
from scipy.optimize import curve_fit
from .pbls import pbls_search
from .sliders import variablewindow_flatten

def gaussian_with_offset(x: np.ndarray, offset: float, amp: float,
                         mu: float, sigma: float) -> np.ndarray:
    """Gaussian plus constant offset model."""
    return offset + amp * np.exp(-0.5 * ((x - mu) / sigma) ** 2)



def find_contiguous_width(x: np.ndarray, y: np.ndarray, idx: int,
                          baseline: float) -> float:
    """Estimate width around a peak where y > baseline.

    Generated by ChatGPT o4-mini on June 11 2025.
    
    Args:
        x: Period axis array.
        y: Power axis array.
        idx: Index of the peak in arrays.
        baseline: Baseline power threshold.
    
    Returns:
        Approximate full width of contiguous region above baseline.
    """
    n = len(x)
    left = idx
    while left > 0 and y[left] > baseline:
        left -= 1
    right = idx
    while right < n - 1 and y[right] > baseline:
        right += 1
    return x[right] - x[left]


def iterative_gaussian_whitening(x: np.ndarray, y: np.ndarray) -> dict:
    """Iteratively fit and subtract peaks until criteria met.

    Generated by ChatGPT o4-mini on June 11 2025.
    
    Args:
        x: Period axis array.
        y: Power axis array (modified in place).
    
    Returns:
        A dict mapping iteration index to a dict with keys:
        'offset','amp','mu','sigma','fwhm','baseline','x','y_start','residual'
    """
    baseline = np.nanpercentile(y, 25)
    results = {}
    fits = 0

    for iter_idx in range(10):
        # cache x and y at start of iteration
        x_start = x.copy()
        y_start = y.copy()

        peak_idx = np.argmax(y)
        peak_power = y[peak_idx]
        peak_period = x[peak_idx]
        if peak_power <= 0:
            break

        width = find_contiguous_width(x, y, peak_idx, baseline)
        window_half = 0.48 * width
        mask = np.abs(x - x[peak_idx]) <= window_half

        # initial guesses: offset, amp, mu, sigma
        p0 = [baseline, peak_power - baseline,
              x[peak_idx], width / (2 * np.sqrt(2 * np.log(2)))]
        bounds = ([0, 0, x[peak_idx] - window_half, 0],
                  [np.inf, np.inf, x[peak_idx] + window_half, 2])

        popt, _ = curve_fit(gaussian_with_offset,
                            x[mask], y[mask], p0=p0, bounds=bounds)

        offset, amp, mu, sigma = popt
        fwhm = 2 * np.sqrt(2 * np.log(2)) * sigma

        print(f"Peak at {mu:.4f} d: power={offset+amp:.3f}, "
              f"FWHM={fwhm:.4f} d")

        fits += 1

        # subtract Gaussian model where y > baseline
        model_vals = gaussian_with_offset(x[mask], *popt)
        subtract_mask = mask & (y > baseline)
        model = gaussian_with_offset(x[subtract_mask], *popt) - offset
        y[subtract_mask] -= model

        # cache residual and all parameters
        residual = y.copy()
        results[iter_idx] = {
            'peak_idx': peak_idx,
            'peak_power': peak_power,
            'peak_period': peak_period,
            'offset': offset,
            'amp': amp,
            'mu': mu,
            'sigma': sigma,
            'fwhm': fwhm,
            'baseline': baseline,
            'x': x_start,
            'y_start': y_start,
            'model': model,
            'subtract_mask': subtract_mask,
            'residual': residual,
        }

        # check break criteria
        if fwhm < 0.05 and (offset + amp) > 7:
            print("Found narrow, high-SNR peak; stopping.")
            found_narrow_peak = True
            results[iter_idx]['found_narrow_peak'] = found_narrow_peak
            return results

        if fits >= 10:
            print("Reached 10 iterations; giving up.")
            found_narrow_peak = False
            results[iter_idx]['found_narrow_peak'] = found_narrow_peak
            return results

    print("No more peaks or zeroed out; done.")
    return results

    
def trimmean_whitening(x: np.ndarray, y: np.ndarray, trim_fraction: float = 0.1,
                       Prot = None) -> dict:
    """
    Args:
        x: Period axis array.
        y: Power axis array (modified in place).
        trim_fraction: Fraction of data to trim from each end of the y array
        Prot: rotation period (days, float)
    
    Returns:
        A dict mapping iteration index to a dict with keys:
        'offset','amp','mu','sigma','fwhm','baseline','x','y_start','residual'
    """
    # TUNABLE HYPERPARAMETERS:
    # * window_length: default window length for flattening (days)
    # * Prot_breakpoint: rotation period threshold to switch methods (days) 
    # * trim_fraction: fraction to trim in trimmean filter
    # * prefactor: width window to use when Prot < Prot_breakpoint
    # * Whether to use trim_mean at all, or else some other smoothing method


    from wotan import flatten

    # points per day; assumes linear period spacing (which from an information
    # theory point of view is ill-advised)
    n = len(x) / (x.max() - x.min())
    window_length = 0.05 # in units of days
    N = n * window_length
    assert float(N) > 5, "Periodogram grid too coarse / Window length too small for trimmean"

    Prot_breakpoint = 3

    if Prot is None or Prot > Prot_breakpoint:
        flat_p, trend_p = flatten(
            x, y, method='trim_mean', window_length=0.05, edge_cutoff=0.,
            break_tolerance=0.5, return_trend=True, proportiontocut=trim_fraction
        )

    else:
        # When Prot < 2 days, there is a forest of peaks in the periodogram that
        # can be whitened by using adaptive window lengths.
        harmonics = np.array([N * Prot for N in range(100)])
        half_harmonics = harmonics + 0.5 * Prot
        merged_harmonics = np.unique(np.concatenate((np.array([0.5*Prot]), harmonics, half_harmonics)))
        sel = (np.nanmin(x) < merged_harmonics) & (merged_harmonics < np.nanmax(x))
        merged_harmonics = merged_harmonics[sel]

        # heuristic to set window widths based on Prot and harmonic number
        # widths get wider for longer trial periods
        prefactor = 1/50 # larger -> wider windows
        window_widths = merged_harmonics * Prot**0.5 * prefactor

        masks = []
        for harmonic, width in zip(merged_harmonics, window_widths):
            in_harmonic_mask = np.abs(x - harmonic) < width / 2
            masks.append(in_harmonic_mask)

        combined_mask = np.any(np.array(masks), axis=0)

        # in the masked regions, use a 5x smaller window length (-> 0.01 days by default)
        window_lengths = np.ones(len(x)) * window_length # default window length
        if np.any(combined_mask):
            window_lengths[combined_mask] = np.ones(len(x[combined_mask])) * window_length / 5

        flat_p, trend_p = variablewindow_flatten(
            x, y, method='trim_mean', window_length=window_lengths,
            edge_cutoff=0., break_tolerance=0.5,
            return_trend=True, proportiontocut=trim_fraction
        )
        
    residual = y - trend_p
    sel = np.isnan(residual)
    residual[sel] = 0
    
    results = {}
    iter_idx = 0

    peak_idx = np.argmax(y)

    results[iter_idx] = {
        'peak_idx': peak_idx,
        'peak_power': y[peak_idx],
        'peak_period': x[peak_idx],
        'offset': 0,
        'amp': None,
        'mu': None,
        'sigma': None,
        'fwhm': None,
        'baseline': None,
        'x': x,
        'y_start': y,
        'model': trend_p,
        'subtract_mask': None,
        'residual': residual,
    }

    iter_idx = 1
    peak_idx = np.argmax(residual)
    model = np.ones(len(residual))*np.nanmedian(residual)
    _residual = residual - model
    results[iter_idx] = {
        'peak_idx': peak_idx,
        'peak_power': residual[peak_idx],
        'peak_period': x[peak_idx],
        'offset': 0,
        'amp': None,
        'mu': None,
        'sigma': None,
        'fwhm': None,
        'baseline': None,
        'x': x,
        'y_start': residual,
        'model': np.ones(len(residual))*np.nanmedian(residual),
        'subtract_mask': None,
        'residual': _residual,
    }

    return results
